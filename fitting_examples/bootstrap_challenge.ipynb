{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This was an example challenge to get familiar with making bootstrapping samples\n",
    "#Bootstrapping samples is a random sample of the original data\n",
    "#data points may be duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's generate 1000 events drawn from a Gaussian distribution and calculate the mean and std dev\n",
    "\n",
    "npts = 1000\n",
    "mu = 10.0\n",
    "sigma = 1.0\n",
    "\n",
    "data = np.random.normal(mu,sigma,npts)\n",
    "\n",
    "print \"calculated mean   : %f\" % (np.mean(data))\n",
    "print \"calculated std dev: %f\" % (np.std(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "plt.hist(data,bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now, generate a \"fake\" dataset of 1000 points randomly drawn from data. \n",
    "# Because you are pulling out 1000 points (the same number as in data), you will have some\n",
    "# repeating data points. That's OK!\n",
    "\n",
    "fake_data=np.random.choice(data,1000)\n",
    "\n",
    "# When you make this fake dataset, calculate the mean\n",
    "\n",
    "print np.mean(fake_data)\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now do this 1000 times, and keep track of all the different means from these mock datasets. \n",
    "# Histogram those means. \n",
    "plt.figure()\n",
    "means=[]\n",
    "stds=[]\n",
    "data=np.array(data)\n",
    "for x in range(1000):\n",
    "    fake_data=np.random.choice(data,1000)\n",
    "    stds.append(np.std(fake_data))\n",
    "    means.append(np.mean(fake_data))\n",
    "plt.hist(means, bins=50)\n",
    "print 'average mean: ', np.mean(means)\n",
    "print 'avergae standard deviation:', np.mean(stds)\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What is the mean of those distributions?\n",
    "\n",
    "# What are the values around the mean that enclose 68% of these mock data means? 95%?\n",
    "'''\n",
    "diff= abs(np.mean(stds)-stds)\n",
    "diff.sort()\n",
    "diff[int(1000*.68)]\n",
    "print np.mean(stds)-diff[int(1000*.68)]\n",
    "print np.mean(stds)+diff[int(1000*.68)]\n",
    "'''\n",
    "diff1= np.mean(stds)-stds\n",
    "diff1.sort()\n",
    "print diff1[(int(1000*.34)-1)]+np.mean(stds)\n",
    "#print diff1\n",
    "print diff1[(int(1000*.84)-1)] +np.mean(stds)\n",
    "print 'mean of stds:',np.mean(stds)\n",
    "print 'std of stds',np.std(stds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def bootstrapping(data):\n",
    "    npts = len(data)\n",
    "    indices = np.random.randint(0,npts,npts)\n",
    "\n",
    "    bs_data= np.array([data[indices].copy()])\n",
    "        \n",
    "    return bs_data\n",
    "\n",
    "# A product of two Gaussians\n",
    "def signal_2D(npts,means,sigmas):\n",
    "    pts = []\n",
    "    for m,s in zip(means,sigmas):\n",
    "        pts.append(np.random.normal(m,s,npts))\n",
    "    pts = np.array(pts)\n",
    "    return pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nMC_sig=1000\n",
    "sigmeans=[5.0,7.0]\n",
    "sigwidths=[0.1,0.1]\n",
    "nsig_iteration=200\n",
    "\n",
    "sig_mean=10.4\n",
    "sig_width=.06\n",
    "signal = np.random.normal(sig_mean,sig_width,nsig_iteration)\n",
    "signal_points= signal_2D(nMC_sig,sigmeans,sigwidths)\n",
    "\n",
    "print len(signal)\n",
    "bootstrapping(np.array(signal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_pull_1D_GPU_bootstrapping(iterations, nsig, nbkg, MC_sig, MC_bkg, num_bootstrapping_samples, nneigh, sig_width,tag):\n",
    "    outfile_name='frac_values_%s_sig%d_bkg%d_MCsig%d_MCbkg%d_bs%d_nn%d.dat'%(tag,nsig,nbkg,MC_sig,MC_bkg,num_bootstrapping_samples,nneigh)\n",
    "    outfile=open(outfile_name,'w')\n",
    "    print 'writing out to file %s' %outfile_name\n",
    "    pull_frac_list=[]\n",
    "    average_best_frac = 0\n",
    "    frac = []\n",
    "    fit_frac = []\n",
    "    fit_frac_uncert = []\n",
    "    my_gpu = numba.cuda.get_current_device()\n",
    "    thread_ct = my_gpu.WARP_SIZE\n",
    "\n",
    "\n",
    "    for num in range(iterations):\n",
    "        nsig_iteration = np.random.poisson(nsig)\n",
    "        nbkg_iteration = np.random.poisson(nbkg)\n",
    "        sig_mean=10.4\n",
    "        sig_width=.06\n",
    "        signal = np.random.normal(sig_mean,sig_width,nsig_iteration)\n",
    "\n",
    "        background = 9.0+(2*np.random.random(nbkg_iteration))\n",
    "        data = signal.copy()\n",
    "        data = np.append(data,background.copy())\n",
    "        signal_compare = np.random.normal(sig_mean,sig_width,MC_sig)\n",
    "        \n",
    "        background_compare= 9.0+(2*np.random.random(MC_bkg))\n",
    "        \n",
    "        \n",
    "        block_ct_sig = int(math.ceil(float(MC_sig*(nsig_iteration+nbkg_iteration)) / thread_ct))\n",
    "        block_ct_bkg = int(math.ceil(float(MC_bkg*(nsig_iteration+nbkg_iteration)) / thread_ct))\n",
    "        signal_distances_GPU = np.zeros((nsig_iteration+nbkg_iteration)*MC_sig, dtype = np.float32)\n",
    "        background_distances_GPU = np.zeros((nsig_iteration+nbkg_iteration)*MC_bkg, dtype = np.float32)\n",
    "\n",
    "        signal_distances=distances_GPU_1D[block_ct_sig, thread_ct](np.float32(data), len(data), np.float32(signal_compare),len(signal_compare), signal_distances_GPU)\n",
    "        background_distances=distances_GPU_1D[block_ct_bkg, thread_ct](np.float32(data), len(data), np.float32(background_compare), len(background_compare), background_distances_GPU)\n",
    "        \n",
    "        signal_prob=sort_GPU_1D((nsig_iteration+nbkg_iteration),MC_sig,np.abs(signal_distances_GPU),nneigh)\n",
    "        background_prob=sort_GPU_1D((nsig_iteration+nbkg_iteration),MC_bkg,np.abs(background_distances_GPU), nneigh)\n",
    "        signal_MC_bs = []\n",
    "        background_MC_bs = []\n",
    "      \n",
    "        \n",
    "\n",
    "        signal_prob_bs = []\n",
    "        background_prob_bs = []\n",
    "        \n",
    "        for i in range(0,num_bootstrapping_samples):\n",
    "            \n",
    "            #Generating bootstrapping samples\n",
    "            signal_MC_bs.append(bootstrapping(signal))\n",
    "            background_MC_bs.append(bootstrapping(background))\n",
    "            \n",
    "            signal_distances_GPU = np.zeros((nsig_iteration+nbkg_iteration)*MC_sig, dtype = np.float32)\n",
    "            background_distances_GPU = np.zeros((nsig_iteration+nbkg_iteration)*MC_bkg, dtype = np.float32)\n",
    "\n",
    "\n",
    "            #calculating distances for each point\n",
    "            signal_distances=distances_GPU_1D[block_ct_sig, thread_ct](np.float32(data), len(data), np.float32(signal_compare),len(signal_compare), signal_distances_GPU)\n",
    "            background_distances=distances_GPU_1D[block_ct_bkg, thread_ct](np.float32(data), len(data), np.float32(background_compare), len(background_compare), background_distances_GPU)\n",
    "        \n",
    "\n",
    "            \n",
    "            signal_prob_bs.append(sort_GPU((nsig_iteration+nbkg_iteration),MC_sig,  np.abs(signal_distances_GPU),nneigh))\n",
    "            background_prob_bs.append(sort_GPU((nsig_iteration+nbkg_iteration),MC_bkg, np.abs(background_distances_GPU),nneigh))\n",
    "            \n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "        def tot_prob(frac,sig,bkg):\n",
    "            tot_prob = frac*sig/MC_sig + ((1-frac)*bkg/MC_bkg)            \n",
    "            return tot_prob\n",
    "        \n",
    "        def probability(frac):\n",
    "            prob= tot_prob(frac,signal_prob,background_prob)\n",
    "            nll= -np.log(prob[prob>0]).sum()\n",
    "            for i in range(0,num_bootstrapping_samples):\n",
    "                prob = tot_prob(frac,signal_prob_bs[i],background_prob_bs[i])\n",
    "                nll +=  -np.log(prob[prob>0]).sum()\n",
    "            return nll\n",
    "            #return -np.log(tot_prob).sum()\n",
    "        \n",
    "        m=Minuit(probability, frac= 0.20, limit_frac=(0.001,1), error_frac=0.001,  errordef = (num_bootstrapping_samples+1)*0.5, print_level=0)\n",
    "        m.migrad()\n",
    "        if (m.get_fmin().is_valid):\n",
    "            param=m.values\n",
    "            err=m.errors\n",
    "            fit_frac.append(param[\"frac\"])\n",
    "            fit_frac_uncert.append(err[\"frac\"])\n",
    "            pull_frac=((float(nsig_iteration)/(float(nbkg_iteration)+float(nsig_iteration)))-param[\"frac\"])/err[\"frac\"]\n",
    "            ndata = len(data)\n",
    "            frac_org = nsig/float(nsig + nbkg)\n",
    "            nsig_org = frac_org * ndata\n",
    "            nsig_fit = param[\"frac\"]\n",
    "            nsig_err = err[\"frac\"]\n",
    "            pull_frac_list.append(pull_frac)\n",
    "            output=\"%f %f %f %d %d %d %d %d %d %d %d\\n\" % (frac_org,param[\"frac\"],err[\"frac\"], nsig,nsig_iteration,nbkg,nbkg_iteration,MC_sig,MC_bkg,num_bootstrapping_samples,nneigh)\n",
    "            outfile.write(output)\n",
    "    outfile.close()\n",
    "    return pull_frac_list, frac, fit_frac, fit_frac_uncert,iterations,outfile_name\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calulates the pulls for the mean and std.\n",
    "def calc_pull_w_bootstrapping_GPU(pull_iterations, nsig, nbkg,nMC_sig, nMC_bkg, num_bootstrapping_samples,  nneigh,sigwidths, tag=\"default\"):\n",
    "    outfile_name='frac_values_%s_sig%d_bkg%d_MCsig%d_MCbkg%d_bs%d_nn%d.dat'%(tag,nsig,nbkg,nMC_sig,nMC_bkg,num_bootstrapping_samples,nneigh)\n",
    "    outfile=open(outfile_name,'w')\n",
    "    print 'writing out to file %s' %outfile_name\n",
    "    \n",
    "    pull_frac_list=[]\n",
    "    average_best_frac = 0\n",
    "    frac = []\n",
    "    fit_frac = []\n",
    "    fit_frac_uncert = []\n",
    "    frac_org = nsig/float(nsig+nbkg)\n",
    "    my_gpu = numba.cuda.get_current_device()\n",
    "    thread_ct = my_gpu.WARP_SIZE\n",
    "\n",
    "    for num in range(pull_iterations):        \n",
    "        # Generate the data for this pull iteration\n",
    "        nsig_iteration = np.random.poisson(nsig)\n",
    "        nbkg_iteration = np.random.poisson(nbkg)\n",
    "        data = gen_sig_and_bkg([nsig_iteration,nbkg_iteration],sigmeans,sigwidths,bkglos,bkghis)\n",
    "\n",
    "        # Record the original amount of signal and background data\n",
    "        #frac_iteration = float(nsig_iteration)/(float(nbkg_iteration+nsig_iteration))\n",
    "        #frac.append(frac_iteration)\n",
    "                \n",
    "        # Generate the MC we will use to try to fit the data we just generated!\n",
    "        signal_points= signal_2D(nMC_sig,sigmeans,sigwidths)\n",
    "        background_points = background_2D(nMC_bkg,bkglos,bkghis)\n",
    "\n",
    "        #Block count\n",
    "        block_ct_sig = int(math.ceil(float(nMC_sig*(nsig_iteration+nbkg_iteration)) / thread_ct))\n",
    "        block_ct_bkg = int(math.ceil(float(nMC_bkg*(nsig_iteration+nbkg_iteration)) / thread_ct))\n",
    "        \n",
    "        #setting up arrays for distances between data points and background MC and data points and signal MC\n",
    "        signal_distances_GPU = np.zeros((nsig_iteration+nbkg_iteration)*nMC_sig, dtype = np.float32)\n",
    "        background_distances_GPU = np.zeros((nsig_iteration+nbkg_iteration)*nMC_bkg, dtype = np.float32)\n",
    "        \n",
    "        #Calculating the distances between data points and MC\n",
    "        signal_distances=distances_GPU[block_ct_sig, thread_ct](np.float32(data[0]), np.float32(data[1]), len(data[1]), np.float32(signal_points[0]), np.float32(signal_points[1]),len(signal_points[1]), signal_distances_GPU)\n",
    "            \n",
    "        background_distances=distances_GPU[block_ct_bkg, thread_ct](np.float32(data[0]), np.float32(data[1]), len(data[1]), np.float32(background_points[0]), np.float32(background_points[1]),len(background_points[1]), background_distances_GPU)\n",
    "        \n",
    "        #sorting the distances\n",
    "        signal_prob=    sort_GPU((nsig_iteration+nbkg_iteration),nMC_sig,signal_distances_GPU,    nneigh)\n",
    "        background_prob=sort_GPU((nsig_iteration+nbkg_iteration),nMC_bkg,background_distances_GPU,nneigh)\n",
    "     \n",
    "\n",
    "        # Generate MC bootstrap samples and calculate the probs for each\n",
    "        signal_MC_bs = []\n",
    "        background_MC_bs = []\n",
    "      \n",
    "        \n",
    "\n",
    "        signal_prob_bs = []\n",
    "        background_prob_bs = []\n",
    "        for i in range(0,num_bootstrapping_samples):\n",
    "            \n",
    "            #Generating bootstrapping samples\n",
    "            signal_MC_bs.append(bootstrapping(signal_points))\n",
    "            background_MC_bs.append(bootstrapping(background_points))\n",
    "            \n",
    "            signal_distances_GPU = np.zeros((nsig_iteration+nbkg_iteration)*nMC_sig, dtype = np.float32)\n",
    "            background_distances_GPU = np.zeros((nsig_iteration+nbkg_iteration)*nMC_bkg, dtype = np.float32)\n",
    "\n",
    "\n",
    "            #calculating distances for each point\n",
    "            signal_distances=distances_GPU[block_ct_sig, thread_ct](np.float32(data[0]), np.float32(data[1]), len(data[1]), np.float32(signal_MC_bs[i][0]), np.float32(signal_MC_bs[i][1]),len(signal_MC_bs[i][1]), signal_distances_GPU)\n",
    "            \n",
    "            background_distances=distances_GPU[block_ct_bkg, thread_ct](np.float32(data[0]), np.float32(data[1]), len(data[1]), np.float32(background_MC_bs[i][0]), np.float32(background_MC_bs[i][1]),len(background_MC_bs[i][1]), background_distances_GPU)\n",
    "            \n",
    "            #print signal_distances_GPU\n",
    "            #print background_distances_GPU\n",
    "            \n",
    "            #sorting distances\n",
    "            signal_prob_bs.append(sort_GPU((nsig_iteration+nbkg_iteration),nMC_sig,signal_distances_GPU,nneigh))\n",
    "            background_prob_bs.append(sort_GPU((nsig_iteration+nbkg_iteration),nMC_bkg,background_distances_GPU,nneigh))\n",
    "            \n",
    "            #print signal_prob_bs[i]\n",
    "            #print background_prob_bs[i]\n",
    "           \n",
    "\n",
    "        \n",
    "        def tot_prob(frac,sig,bkg):\n",
    "            tot_prob = frac*sig/nMC_sig + ((1-frac)*bkg/nMC_bkg)            \n",
    "            return tot_prob\n",
    "        \n",
    "        def negative_log_likelihood(frac):\n",
    "            \n",
    "            # First, use the original MC/probs to calculate the NLL\n",
    "            prob=tot_prob(frac,signal_prob,background_prob)\n",
    "            #prob = np.float64(prob)\n",
    "            nll =  -np.log(prob[prob>0]).sum()\n",
    "            \n",
    "            # Then add in the prob/NLLs for the bootstrap samples\n",
    "            for i in range(0,num_bootstrapping_samples):\n",
    "                prob = tot_prob(frac,signal_prob_bs[i],background_prob_bs[i])\n",
    "                nll +=  -np.log(prob[prob>0]).sum()\n",
    "            #print nll\n",
    "            #print type(nll)\n",
    "            return nll\n",
    "        \n",
    "        m1=Minuit(negative_log_likelihood,frac= 0.2,limit_frac=(0.001,1),error_frac=0.001,errordef =(num_bootstrapping_samples+1)*0.5,print_level=0)\n",
    "        #m1.tol = num_bootstrapping_samples\n",
    "        m1.migrad()\n",
    "        #m1.hesse()\n",
    "\n",
    "        if (m1.get_fmin().is_valid):\n",
    "            param=m1.values\n",
    "            err=m1.errors\n",
    "            fit_frac.append(param[\"frac\"])\n",
    "            fit_frac_uncert.append(err[\"frac\"])\n",
    "            pull_frac=(frac_org-param[\"frac\"])/err[\"frac\"]\n",
    "            pull_frac_list.append(pull_frac)\n",
    "            \n",
    "            output=\"%f %f %f %d %d %d %d %d %d %d %d\\n\" % (frac_org,param[\"frac\"],err[\"frac\"], nsig,nsig_iteration,nbkg,nbkg_iteration,nMC_sig,nMC_bkg,num_bootstrapping_samples,nneigh)\n",
    "            #print output\n",
    "            outfile.write(output)\n",
    "    outfile.close()\n",
    "    return pull_frac_list, frac, fit_frac, fit_frac_uncert,pull_iterations,outfile\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
