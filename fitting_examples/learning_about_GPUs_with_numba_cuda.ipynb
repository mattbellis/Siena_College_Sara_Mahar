{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "import math\n",
    "\n",
    "# For GPU stuff\n",
    "from numba import cuda\n",
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU: GeForce GTX TITAN X\n",
      "Compute capability:  5.2 \n",
      "Number of streaming pultiprocess: 24\n",
      "Number of cores per multiprocessor: 128\n",
      "Number of cores on GPU: 3072\n",
      "Max dimension size of a thread block (x, y, z): ( 1024 , 1024 , 64 )\n",
      "Maximum number of threads per block: 1024\n",
      "Max dimension size of a thread block (x, y, z): ( 2147483647 , 2147483647 , 65535 )\n",
      "Warp Size:         32\n"
     ]
    }
   ],
   "source": [
    "# Basic device query\n",
    "\n",
    "my_gpu = numba.cuda.get_current_device()\n",
    "\n",
    "print \"Running on GPU:\", my_gpu.name\n",
    "cores_per_capability = {\n",
    "\t1: 8,\n",
    "\t2: 32,\n",
    "\t3: 192,\n",
    "    5: 128,\n",
    "}\n",
    "\n",
    "cc = my_gpu.compute_capability\n",
    "print \"Compute capability: \", \"%d.%d\" %cc, \n",
    "majorcc = cc[0]\n",
    "print \"\\nNumber of streaming pultiprocess:\", my_gpu.MULTIPROCESSOR_COUNT\n",
    "cores_per_multiprocessor = cores_per_capability[majorcc]\n",
    "print \"Number of cores per multiprocessor:\", cores_per_multiprocessor\n",
    "total_cores = cores_per_multiprocessor * my_gpu.MULTIPROCESSOR_COUNT\n",
    "print \"Number of cores on GPU:\", total_cores\n",
    "\n",
    "xDim = my_gpu.MAX_BLOCK_DIM_X\n",
    "yDim = my_gpu.MAX_BLOCK_DIM_Y\n",
    "zDim = my_gpu.MAX_BLOCK_DIM_Z\n",
    "print \"Max dimension size of a thread block (x, y, z): (\", xDim, \",\", yDim, \",\",zDim,\")\"\n",
    "print \"Maximum number of threads per block:\",  my_gpu.MAX_THREADS_PER_BLOCK\n",
    "xGrid = my_gpu.MAX_GRID_DIM_X\n",
    "yGrid = my_gpu.MAX_GRID_DIM_X\n",
    "zGrid = my_gpu.MAX_GRID_DIM_Z\n",
    "print \"Max dimension size of a thread block (x, y, z): (\", xGrid, \",\", yGrid, \",\",zGrid,\")\"\n",
    "print \"Warp Size:        \", my_gpu.WARP_SIZE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16777216\n",
      "[  1.00000000e+00   2.00000000e+00   3.00000000e+00 ...,   1.67772140e+07\n",
      "   1.67772150e+07   1.67772160e+07]\n"
     ]
    }
   ],
   "source": [
    "# Squaring each element of an array\n",
    "\n",
    "npts = 16777216\n",
    "\n",
    "data = 1.*np.arange(1,npts+1)\n",
    "print len(data)\n",
    "print data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def square_CPU(x):\n",
    "    out = np.zeros(len(x))\n",
    "    for i in range(0,len(x)):\n",
    "        out[i] = x[i]*x[i]\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This took 3.95621204376 seconds\n",
      "[  1.00000000e+00   4.00000000e+00   9.00000000e+00 ...,   2.81474910e+14\n",
      "   2.81474943e+14   2.81474977e+14]\n"
     ]
    }
   ],
   "source": [
    "# Test it!\n",
    "start = time.time()\n",
    "s0 = square_CPU(data)\n",
    "print \"This took %s seconds\" % (time.time()-start)\n",
    "print s0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do the same on the GPU\n",
    "\n",
    "@numba.cuda.jit(\"void(float64[:],float64[:])\")\n",
    "def square_GPU(data_in,data_out):\n",
    "    \n",
    "    tx = cuda.threadIdx.x #number of threads per block\n",
    "    bx = cuda.blockIdx.x #number of blocks\n",
    "    bw = cuda.blockDim.x # Block dimension/width to assign the index when there is more than 1 block\n",
    "    \n",
    "    idx = bw*bx + tx\n",
    "    \n",
    "    x = data_in[idx]\n",
    "    \n",
    "    #data_out[idx] = x*x\n",
    "    data_out[idx] = math.log(x*x) * math.sin(x) * math.cos(x)\n",
    "    #data_out[idx] = bx\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524288 32\n"
     ]
    }
   ],
   "source": [
    "#Set the thread count to the number of threads on our GPU\n",
    "thread_ct = my_gpu.WARP_SIZE\n",
    "#Set the block count\n",
    "block_ct = int(math.ceil(float(npts) / thread_ct))\n",
    "\n",
    "print block_ct,thread_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This took 0.167119026184 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "data_out = -999*np.ones(len(data))\n",
    "square_GPU[block_ct,thread_ct](data,data_out)\n",
    "print \"This took %s seconds\" % (time.time()-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for d in data_out:\n",
    "#    print d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.57412230169e+21\n"
     ]
    }
   ],
   "source": [
    "print (data_out-s0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This took 1.59368300438 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "s1 = np.log(data*data) * np.sin(data) * np.cos(data)\n",
    "print \"This took %s seconds\" % (time.time()-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.59633468156e-09\n"
     ]
    }
   ],
   "source": [
    "print np.abs((data_out-s1)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
